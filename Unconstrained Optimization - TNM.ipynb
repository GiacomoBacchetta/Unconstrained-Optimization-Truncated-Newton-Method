{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e92d7708",
   "metadata": {},
   "source": [
    "# Unconstrained optimization: the Truncated Newton Method\n",
    "* ## Giacomo Bacchetta, bacchetta.1840949@studenti.uniroma1.it\n",
    "* ## Edoardo Cesaroni, cesaroni.1841742@studenti.uniroma1.it \n",
    "* ## Fabio Ciccarelli, ciccarelli.1835348@studenti.uniroma1.it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f3be56",
   "metadata": {},
   "source": [
    "## Support's functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8de1a7",
   "metadata": {},
   "source": [
    "We import the python libraries useful for the implementation of the method. These are:\n",
    "- $\\bf{Autograd.numpy}$, which allows us to use siple mathematical functions;\n",
    "- $\\bf{Autograd}$, used to calculate the gradient (*grad*) of several functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2725733",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb645c7b",
   "metadata": {},
   "source": [
    "## Armijo Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82909a44",
   "metadata": {},
   "source": [
    "The $\\bf{Armijo}$ condition is a line search method used to determine the amount to move along a given search direction. This line search algorithm can be expressed as follows:\n",
    "1. Set $ \\alpha > 0,\\delta \\in (0,1), \\gamma \\in (0,\\frac{1}{2})$\n",
    "2. Until the condition is satisfied that $f(x_k + \\alpha \\cdot d) > f(x_k) + \\alpha \\cdot \\gamma \\cdot (\\nabla(f(x_k)) \\times  d)$, then $\\alpha = \\alpha \\cdot \\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9ff516d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo(f, x_k, d):\n",
    "    alpha = 1\n",
    "    delta = 0.5\n",
    "    gamma = 1e-3\n",
    "\n",
    "    while True:\n",
    "        if f(x_k + alpha*d) > f(x_k) + alpha * gamma * (grad(f)(x_k) @ d):\n",
    "            alpha = delta * alpha\n",
    "        else:\n",
    "            return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8cb0fe",
   "metadata": {},
   "source": [
    "## Other useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef4a49a",
   "metadata": {},
   "source": [
    "The $\\bf{mxv}$ function has the goal to return the result of the product between a matrix and a vector. We used a trick suggested by our professor.\\\n",
    "The $\\bf{gradfi}$ function insted has the goal to return the sum between the value of *mxv* and the value of the gradient of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "009a782b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mxv(v, f, x):\n",
    "    eta = 1e-6\n",
    "    x_succ = x + eta*v\n",
    "    return (grad(f)(x_succ) - grad(f)(x))/eta\n",
    "\n",
    "\n",
    "def gradfi(d,f,x):\n",
    "    return mxv(d,f,x) + grad(f)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d9caea9",
   "metadata": {},
   "source": [
    "# Truncated Newton Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73588c63",
   "metadata": {},
   "source": [
    "## Descent direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "267b093a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(f, x, k):\n",
    "\n",
    "    epsilon_1 = 0.5\n",
    "    epsilon_2 = 0.5\n",
    "    p = 0\n",
    "\n",
    "    s = -(gradfi(p, f, x))\n",
    "    \n",
    "    if (s @ mxv(s, f, x)) < (epsilon_1 * (np.linalg.norm(s))**2):\n",
    "        d = -(grad(f)(x))\n",
    "        return d\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if (s @ mxv(s, f, x)) <= 1e-6:              #default = 1e-9\n",
    "            return -grad(f)(x)\n",
    "        \n",
    "        alfa = -((gradfi(p, f, x) @ s) / (s @ mxv(s, f, x)))\n",
    "        p = p + alfa * s\n",
    "\n",
    "        if np.linalg.norm(gradfi(p, f, x)) <= (1/(k+1))*epsilon_2*(np.linalg.norm(grad(f)(x))):\n",
    "            d = p\n",
    "            return d\n",
    "        \n",
    "        else:\n",
    "            beta = (gradfi(p, f, x) @ mxv(s, f, x)) / (s @ mxv(s, f, x))\n",
    "            s = -(gradfi(p, f, x)) + beta * s\n",
    "\n",
    "            if (s @ mxv(s, f, x)) < (epsilon_1 * (np.linalg.norm(s))**2):\n",
    "                d = p\n",
    "                return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e33cb78c",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ae7fa7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt(f, x, eps = 1e-5):  \n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    if np.linalg.norm(grad(f)(x)) < eps:\n",
    "        return x\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        d = dt(f, x, k)\n",
    "        a = armijo(f, x, d)\n",
    "        x = x + a * d\n",
    "        \n",
    "        if np.linalg.norm(grad(f)(x)) <= eps:\n",
    "            print('NT: STOP! The optimum point is:', x, 'The optimum value of the objective function is:', f(x))\n",
    "            return x\n",
    "        \n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38813d7",
   "metadata": {},
   "source": [
    "## Implementation test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "602c23e8",
   "metadata": {},
   "source": [
    "From now on, we will define unconstrained problems to which we will apply our method. The solutions can be compared with those on the attached pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb54e29",
   "metadata": {},
   "source": [
    "### Wood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e11e1680",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.9999997  0.99999942 1.00000029 1.00000058] The optimum value of the objective function is: 3.5382965525386403e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.9999997 , 0.99999942, 1.00000029, 1.00000058])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def x0_wood():\n",
    "    x = np.array([-3. ,-1. ,-3. ,-1.])\n",
    "    return x\n",
    "\n",
    "def wood(x):\n",
    "    return 100*(x[0]**2-x[1])**2 + (x[0]-1.)**2 + (x[2]-1.)**2 + 90.*(x[2]**2-x[3])**2 + 10.1*((x[1]-1.)**2 + (x[3]-1.)**2.) + 19.8*(x[1]-1.)*(x[3]-1.)\n",
    "\n",
    "nt(wood, x0_wood())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d4dd4c",
   "metadata": {},
   "source": [
    "### Scaled Rosenbrock Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "915d5276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99998953 0.99997901] The optimum value of the objective function is: 1.0984076605996073e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99998953, 0.99997901])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rosenbrock(x):\n",
    "    return sum((100*(x[i+1]-x[i]**2)**2 + (1-x[i])**2) for i in range(len(x)-1))\n",
    "\n",
    "def x0_rosenbrock(n):\n",
    "    x_0 = np.zeros(n)\n",
    "    for i in range(0, n-1, 2):\n",
    "        x_0[i] = -1.2\n",
    "        x_0[i+1] = 1\n",
    "    return x_0\n",
    "\n",
    "nt(rosenbrock, x0_rosenbrock(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26257530",
   "metadata": {},
   "source": [
    "### Cube Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff050ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99998586 0.99995755] The optimum value of the objective function is: 1.9998358443222965e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99998586, 0.99995755])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def x0_cube():\n",
    "    return np.array([-1.2,1])\n",
    "\n",
    "def cube(x):\n",
    "    c=10**2\n",
    "    return c*(x[1]-x[0]**3)**2 + (1-x[0])**2\n",
    "\n",
    "nt(cube, x0_cube())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d0431b",
   "metadata": {},
   "source": [
    "### Powell Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cbd463b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [ 0.00526472  0.01053906 -0.00105385  0.0052638 ] The optimum value of the objective function is: 2.5734175685533454e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00526472,  0.01053906, -0.00105385,  0.0052638 ])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def powell(x):\n",
    "    n = len(x)\n",
    "    return sum((x[4*i-3]+10*x[4*i-2])**2+5*(x[4*i-1]-x[4*i])**2 + (x[4*i-2]-2*x[4*i-1])**4 + 10*(x[4*i-3]-x[4*i])**4 for i in range(int(n/4)))\n",
    "\n",
    "def x0_powell(n):\n",
    "    x = np.zeros(n)\n",
    "    for i in range(0, n, 4):\n",
    "        x[i] = 3\n",
    "        x[i+1] = -1\n",
    "        x[i+2] = 0\n",
    "        x[i+3] = 1\n",
    "    return x\n",
    "\n",
    "nt(powell, x0_powell(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf97c2d6",
   "metadata": {},
   "source": [
    "### Dixon Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d5af063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [1.00000014 0.70710676 0.59460369 0.5452538 ] The optimum value of the objective function is: 8.037140838754466e-13\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000014, 0.70710676, 0.59460369, 0.5452538 ])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dixon(x):\n",
    "    return (x[0]-1)**2 + sum(i*(2*(x[i-1]**2)-x[i-1-1])**2 for i in range(2,len(x)+1))\n",
    "\n",
    "def x0_dixon(n):\n",
    "    return np.ones(n)\n",
    "\n",
    "nt(dixon, x0_dixon(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89a43c9",
   "metadata": {},
   "source": [
    "### Box Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6ba7b4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [ 0.99944231 10.00783691  1.00041323] The optimum value of the objective function is: 2.8216865043807813e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99944231, 10.00783691,  1.00041323])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def box(x):\n",
    "    return sum((np.exp(-0.1*i*x[0])-np.exp(-0.1*i*x[1])-x[2]*(np.exp(-0.1*i)-np.exp(-i)))**2 for i in range(1, 11))\n",
    "\n",
    "def x0_box():\n",
    "    return np.array([0. ,10. ,20.])\n",
    "\n",
    "nt(box, x0_box())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b8502",
   "metadata": {},
   "source": [
    "### Oren Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "028556c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [1.00000000e+00 1.35602946e-02 2.77855991e-04 1.04515931e-05] The optimum value of the objective function is: 3.386936940310604e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.35602946e-02, 2.77855991e-04, 1.04515931e-05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oren(x):\n",
    "    f = 0\n",
    "    for i in range (0,len(x)):\n",
    "        f+= (i*(x[i]**2))\n",
    "    return f**2\n",
    "\n",
    "def x0_oren(n):\n",
    "    x_1=np.zeros(n)\n",
    "    for i in range (0,n):\n",
    "        x_1[i]=1\n",
    "    return x_1 \n",
    "\n",
    "nt(oren, x0_oren(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8fb6ca",
   "metadata": {},
   "source": [
    "### Separated Rose Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47320a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99999421 0.9999883  0.99999421 0.9999883 ] The optimum value of the objective function is: 6.729669532033541e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999421, 0.9999883 , 0.99999421, 0.9999883 ])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separatedRose(x):\n",
    "    f=0\n",
    "    c=10.**1\n",
    "    for j in range(0,len(x),2):\n",
    "        f = f + (1. - x[j])**2 + c*(x[j+1] - x[j]**2)**2\n",
    "    return f\n",
    "\n",
    "def x0_separatedRose(n):\n",
    "    x=np.zeros(n)\n",
    "    for i in range(0,n,2):\n",
    "        x[i]=-1.2\n",
    "        x[i+1]=1\n",
    "    return x\n",
    "\n",
    "nt(separatedRose, x0_separatedRose(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
