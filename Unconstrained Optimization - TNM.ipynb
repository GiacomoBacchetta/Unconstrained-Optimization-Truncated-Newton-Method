{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "adc5462f",
   "metadata": {},
   "source": [
    "# Unconstrained optimization: the Truncated Newton Method\n",
    "* ## Giacomo Bacchetta, bacchetta.1840949@studenti.uniroma1.it\n",
    "* ## Edoardo Cesaroni, cesaroni.1841742@studenti.uniroma1.it \n",
    "* ## Fabio Ciccarelli, ciccarelli.1835348@studenti.uniroma1.it "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88315f66",
   "metadata": {},
   "source": [
    "## Support's functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b331e44",
   "metadata": {},
   "source": [
    "We import the python libraries useful for the implementation of the method. These are:\n",
    "- $\\bf{Autograd.numpy}$, which allows us to use simple mathematical functions;\n",
    "- $\\bf{Autograd}$, used to calculate the gradient (*grad*) of several functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00220354",
   "metadata": {},
   "outputs": [],
   "source": [
    "import autograd.numpy as np\n",
    "from autograd import grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b641dfcf",
   "metadata": {},
   "source": [
    "## Armijo Condition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d4098e",
   "metadata": {},
   "source": [
    "The $\\bf{Armijo}$ condition is a line search method used to determine the amount to move along a given search direction. This line search algorithm can be expressed as follows:\n",
    "1. Set $ \\alpha > 0,\\delta \\in (0,1), \\gamma \\in (0,\\frac{1}{2})$\n",
    "2. Until the condition is satisfied that $f(x_k + \\alpha \\cdot d) > f(x_k) + \\alpha \\cdot \\gamma \\cdot (\\nabla(f(x_k)) \\times  d)$, then $\\alpha = \\alpha \\cdot \\delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91b1c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def armijo(f, x_k, d):\n",
    "    alpha = 1\n",
    "    delta = 0.5\n",
    "    gamma = 1e-3\n",
    "\n",
    "    while True:\n",
    "        if f(x_k + alpha*d) > f(x_k) + alpha * gamma * (grad(f)(x_k) @ d):\n",
    "            alpha = delta * alpha\n",
    "        else:\n",
    "            return alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822c078",
   "metadata": {},
   "source": [
    "## Other useful functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b72f12",
   "metadata": {},
   "source": [
    "The $\\bf{mxv}$ function has the goal to return the result of the product between a matrix and a vector. In particular, we applied the incremental ratio formula to carry out this multiplication.\\\n",
    "The $\\bf{gradfi}$ function insted has the goal to return the sum between the value of *mxv* and the value of the gradient of the objective function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed76665a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mxv(v, f, x):\n",
    "    eta = 1e-6\n",
    "    x_succ = x + eta*v\n",
    "    return (grad(f)(x_succ) - grad(f)(x))/eta\n",
    "\n",
    "\n",
    "def gradfi(d,f,x):\n",
    "    return mxv(d,f,x) + grad(f)(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40650386",
   "metadata": {},
   "source": [
    "# Truncated Newton Method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3d87ca",
   "metadata": {},
   "source": [
    "## Descent direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfda29f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dt(f, x, k):\n",
    "\n",
    "    epsilon_1 = 0.5\n",
    "    epsilon_2 = 0.5\n",
    "    p = 0\n",
    "    \n",
    "    s = -grad(f)(x)\n",
    "    \n",
    "    if (s @ mxv(s, f, x)) < (epsilon_1 * (np.linalg.norm(s))**2):\n",
    "        d = -(grad(f)(x))\n",
    "        return d\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        if (s @ mxv(s, f, x)) <= 1e-9:              #default = 1e-9\n",
    "            return -grad(f)(x)\n",
    "        \n",
    "        alfa = -((gradfi(p, f, x) @ s) / (s @ mxv(s, f, x)))\n",
    "        p = p + alfa * s\n",
    "\n",
    "        if np.linalg.norm(gradfi(p, f, x)) <= (1/(k+1))*epsilon_2*(np.linalg.norm(grad(f)(x))):\n",
    "            d = p\n",
    "            return d\n",
    "        \n",
    "        else:\n",
    "            beta = (gradfi(p, f, x) @ mxv(s, f, x)) / (s @ mxv(s, f, x))\n",
    "            s = -(gradfi(p, f, x)) + beta * s\n",
    "\n",
    "            if (s @ mxv(s, f, x)) < (epsilon_1 * (np.linalg.norm(s))**2):\n",
    "                d = p\n",
    "                return d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4569093",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8c0720fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def nt(f, x, eps = 1e-5):  \n",
    "    \n",
    "    k = 0\n",
    "    \n",
    "    if np.linalg.norm(grad(f)(x)) < eps:\n",
    "        return x\n",
    "    \n",
    "    while True:\n",
    "        \n",
    "        d = dt(f, x, k)\n",
    "        a = armijo(f, x, d)\n",
    "        x = x + a * d\n",
    "        \n",
    "        if np.linalg.norm(grad(f)(x)) <= eps:\n",
    "            print('NT: STOP! The optimum point is:', x, 'The optimum value of the objective function is:', f(x))\n",
    "            return x\n",
    "        \n",
    "        k = k + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f489c02",
   "metadata": {},
   "source": [
    "## Implementation test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48914d6",
   "metadata": {},
   "source": [
    "From now on, we will define unconstrained problems to which we will apply our method. The solutions can be compared with those on the attached pdf file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b222eae1",
   "metadata": {},
   "source": [
    "### Wood Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7f8bf85f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [1.00000001 1.00000002 1.         1.        ] The optimum value of the objective function is: 2.2733433534941187e-15\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000001, 1.00000002, 1.        , 1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def x0_wood():\n",
    "    x = np.array([-3. ,-1. ,-3. ,-1.])\n",
    "    return x\n",
    "\n",
    "def wood(x):\n",
    "    return 100*(x[0]**2-x[1])**2 + (x[0]-1.)**2 + (x[2]-1.)**2 + 90.*(x[2]**2-x[3])**2 + 10.1*((x[1]-1.)**2 + (x[3]-1.)**2.) + 19.8*(x[1]-1.)*(x[3]-1.)\n",
    "\n",
    "nt(wood, x0_wood())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e32c02",
   "metadata": {},
   "source": [
    "### Scaled Rosenbrock Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7ddca69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99999211 0.99998419] The optimum value of the objective function is: 6.237058410058728e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999211, 0.99998419])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rosenbrock(x):\n",
    "    return sum((100*(x[i+1]-x[i]**2)**2 + (1-x[i])**2) for i in range(len(x)-1))\n",
    "\n",
    "def x0_rosenbrock(n):\n",
    "    x_0 = np.zeros(n)\n",
    "    for i in range(0, n-1, 2):\n",
    "        x_0[i] = -1.2\n",
    "        x_0[i+1] = 1\n",
    "    return x_0\n",
    "\n",
    "nt(rosenbrock, x0_rosenbrock(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ebd761",
   "metadata": {},
   "source": [
    "### Cube Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "145f36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99998505 0.9999551 ] The optimum value of the objective function is: 2.2380602998052338e-10\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99998505, 0.9999551 ])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def x0_cube():\n",
    "    return np.array([-1.2, 1])\n",
    "\n",
    "def cube(x):\n",
    "    c = 10**2\n",
    "    return c*(x[1] - x[0]**3) **2 + (1 - x[0])**2\n",
    "\n",
    "nt(cube, x0_cube())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb587071",
   "metadata": {},
   "source": [
    "### Powell Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b2b2928",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [ 0.00553509  0.01106667 -0.00110665  0.00553417] The optimum value of the objective function is: 3.1339119924221176e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.00553509,  0.01106667, -0.00110665,  0.00553417])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def powell(x):\n",
    "    n = len(x)\n",
    "    return sum((x[4*i-3]+10*x[4*i-2])**2+5*(x[4*i-1]-x[4*i])**2 + (x[4*i-2]-2*x[4*i-1])**4 + 10*(x[4*i-3]-x[4*i])**4 for i in range(int(n/4)))\n",
    "\n",
    "def x0_powell(n):\n",
    "    x = np.zeros(n)\n",
    "    for i in range(0, n, 4):\n",
    "        x[i] = 3\n",
    "        x[i+1] = -1\n",
    "        x[i+2] = 0\n",
    "        x[i+3] = 1\n",
    "    return x\n",
    "\n",
    "nt(powell, x0_powell(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a849093",
   "metadata": {},
   "source": [
    "### Dixon Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4ed26a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [1.00000001 0.70710679 0.59460356 0.54525387] The optimum value of the objective function is: 2.434268857130223e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000001, 0.70710679, 0.59460356, 0.54525387])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def dixon(x):\n",
    "    return (x[0]-1)**2 + sum(i*(2*(x[i-1]**2)-x[i-1-1])**2 for i in range(2,len(x)+1))\n",
    "\n",
    "def x0_dixon(n):\n",
    "    return np.ones(n)\n",
    "\n",
    "nt(dixon, x0_dixon(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53a27b5f",
   "metadata": {},
   "source": [
    "### Box Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35f079d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [ 0.99925515 10.01046526  1.00055092] The optimum value of the objective function is: 5.0312378567305434e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 0.99925515, 10.01046526,  1.00055092])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def box(x):\n",
    "    return sum((np.exp(-0.1*i*x[0])-np.exp(-0.1*i*x[1])-x[2]*(np.exp(-0.1*i)-np.exp(-i)))**2 for i in range(1, 11))\n",
    "\n",
    "def x0_box():\n",
    "    return np.array([0. ,10. ,20.])\n",
    "\n",
    "nt(box, x0_box())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef982f5",
   "metadata": {},
   "source": [
    "### Oren Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "278f43a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [1.00000000e+00 1.35602946e-02 2.77855991e-04 1.04515931e-05] The optimum value of the objective function is: 3.386936940310604e-08\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.00000000e+00, 1.35602946e-02, 2.77855991e-04, 1.04515931e-05])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def oren(x):\n",
    "    f = 0\n",
    "    for i in range (0,len(x)):\n",
    "        f += (i*(x[i]**2))\n",
    "    return f**2\n",
    "\n",
    "def x0_oren(n):\n",
    "    x_1 = np.zeros(n)\n",
    "    for i in range (0,n):\n",
    "        x_1[i] = 1\n",
    "    return x_1 \n",
    "\n",
    "nt(oren, x0_oren(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c136ae",
   "metadata": {},
   "source": [
    "### Separated Rose Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0ed800a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NT: STOP! The optimum point is: [0.99999401 0.99998768 0.99999401 0.99998768] The optimum value of the objective function is: 7.41272103708261e-11\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.99999401, 0.99998768, 0.99999401, 0.99998768])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def separatedRose(x):\n",
    "    f = 0\n",
    "    c = 10.**1\n",
    "    for j in range(0,len(x),2):\n",
    "        f = f + (1. - x[j])**2 + c*(x[j+1] - x[j]**2)**2\n",
    "    return f\n",
    "\n",
    "def x0_separatedRose(n):\n",
    "    x = np.zeros(n)\n",
    "    for i in range(0,n,2):\n",
    "        x[i] = -1.2\n",
    "        x[i+1] = 1\n",
    "    return x\n",
    "\n",
    "nt(separatedRose, x0_separatedRose(4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
